{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL_Exercise1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3w1twHxVtq9n","colab_type":"text"},"source":["Exercise 1: OpenAI Gym\n","\n","Run the following notebook either on Colab or your local PC."]},{"cell_type":"markdown","metadata":{"id":"7G6qZkUNiFgn","colab_type":"text"},"source":["The following cells are required to enable the display of Gym environment in Colab."]},{"cell_type":"code","metadata":{"id":"pMdDEAwUpXIf","colab_type":"code","colab":{}},"source":["!apt-get install -y xvfb python-opengl > /dev/null 2>&1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePdZQmDBtrM-","colab_type":"code","colab":{}},"source":["!pip3 install gym pyvirtualdisplay > /dev/null 2>&1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EiR7hqGt0R_","colab_type":"code","colab":{}},"source":["import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython import display as ipythondisplay"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IwrU6htMt2Pc","colab_type":"code","colab":{}},"source":["from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(400, 300))\n","display.start()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"toJJzucyiPkn","colab_type":"text"},"source":["Now the display in Colab should be enabled.\n","\n","-------\n","\n","Try the CartPole in OpenAI Gym. First create and reset the environment."]},{"cell_type":"code","metadata":{"id":"n9HN9Hgghxg4","colab_type":"code","colab":{}},"source":["env = gym.make(\"CartPole-v0\")\n","env.reset()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OxFl17Sqinm9","colab_type":"text"},"source":["Next, get the initialize the state by calling render()"]},{"cell_type":"code","metadata":{"id":"bd7BQY7zivSO","colab_type":"code","colab":{}},"source":["state = env.render(mode='rgb_array')\n","plt.imshow(state)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i80uIR72jOde","colab_type":"text"},"source":["Now run the code below for an episodes of 100 or longer. In this game, we only randomly pick actions of moving left or right from the action space, and let it acted by the agent. In each step, the environment returns the next state, reward, and other information to the agent."]},{"cell_type":"code","metadata":{"id":"tzx2QghUporD","colab_type":"code","colab":{}},"source":["for i in range(100):\n","  # randomly sample the actions from the action space\n","  action = env.action_space.sample()\n","  obs, reward, done, info = env.step(action)\n","  screen = env.render(mode='rgb_array')\n","  print(\"action: {},   reward: {}\".format(action, reward))\n","  plt.imshow(screen)\n","  ipythondisplay.clear_output(wait=True)\n","  ipythondisplay.display(plt.gcf())\n","\n","  if done:\n","    break\n","    \n","ipythondisplay.clear_output(wait=True)\n","env.reset()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lOW3B6LnkFtx","colab_type":"text"},"source":["To close the environment, call close()."]},{"cell_type":"code","metadata":{"id":"TlZO8UorkJL6","colab_type":"code","colab":{}},"source":["env.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pGZop8NakpSi","colab_type":"text"},"source":["Now we can try to install gym-retro into the VM and try"]},{"cell_type":"code","metadata":{"id":"qzjIWI9sTksD","colab_type":"code","colab":{}},"source":["!pip3 install gym-retro"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqOm2NcJUKTN","colab_type":"code","colab":{}},"source":["import retro"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzxHOb8pUSk6","colab_type":"code","colab":{}},"source":["env = retro.RetroEnv(game='Airstriker-Genesis', use_restricted_actions=retro.Actions.FILTERED  )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"39zNXifAlihD","colab_type":"text"},"source":["Run the cell below to examine the state, action and their shapes."]},{"cell_type":"code","metadata":{"id":"xjV8sgxpUVss","colab_type":"code","colab":{}},"source":["env.reset()\n","state = env.render('rgb_array')\n","plt.imshow(state)\n","\n","print(\"State space shape = \",env.observation_space.shape)\n","print(\"Action space shape\",env.action_space.shape)\n","print(env.action_space.sample())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w1PLQKQfkjoS","colab_type":"text"},"source":["Finally, to turn off the display on Colab, run the following."]},{"cell_type":"code","metadata":{"id":"alscGS1_pt4u","colab_type":"code","colab":{}},"source":["display.stop()"],"execution_count":0,"outputs":[]}]}